# word2vec

Train the negative sampling skip-gram model with window_size = 5 to encode about 20,000 words from Stanford Treebank dataset in 10 dense dimension, with sgd optimizer.